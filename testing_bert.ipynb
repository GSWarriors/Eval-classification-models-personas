{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of added tokens: 2\n",
      "encoded snippet: [  101 30522  1045  2079  2025  1012  2021  1045  2079  2031  1037  5440\n",
      "  6240  2144  2008  2003  2035  1045  4521  7580  1012 30523  2054  2003\n",
      "  2115  5440  6240  2000  4521  1029 30522  1045  2052  2031  2000  2360\n",
      "  2049  3539 19395  1012  2079  2017  2031  2151  5440  9440  1029 30523\n",
      "  1045  2066  7975  2030  6097 10464  3490  1998  8808  1012   102]\n",
      "\n",
      "encoded snippet: [  101 30522  2008  2003  3835  1012  3566  2015  2024  3492  4658  2205\n",
      "  1012 30523  1045  2572  2036 15677  2007 22322  2015 30522  2057  2035\n",
      "  2444  1999  1037  3756  6982  1010  1037  3756  6982  1012  2851   999\n",
      " 30523  7632   999  2008  2003  1037  2307  2240  2005  2026  2279  3233\n",
      "  2039  1012   102     0     0     0     0     0     0     0     0]\n",
      "\n",
      "encoded snippet: [  101 30522  2428  1012  2021  1010  1045  2064  6170  6510  3819  1012\n",
      " 30523  1045  2036  5660  1010  1998  1045  4536  2026  7997  2000  2147\n",
      "  1012 30522  2307   999  1045  2018  2180  2019  2400  2005 11379 10506\n",
      "  1012 30523  2026 10402  2064  2156  2083  2054  2017  2024  2667  2000\n",
      "  5271  2033  1012   102     0     0     0     0     0     0     0]\n",
      "\n",
      "encoded snippet: [  101 30522  1045  2293 25659  2015  1012  1045  4521 25659  2015  2066\n",
      "  1037  3586  1012 30523  2024  2017  3287  2030  2931  1029 30522  1045\n",
      "  2147  2004  1037  2175  3126 11368  5660  2040  2036  2038  1037  6510\n",
      "  3819  2376  1012 30523  1045  4797  2008  2200  2172  1012  2017  2763\n",
      "  2066  2000  6978  2894  1012   102     0     0     0     0     0]\n",
      "\n",
      "encoded snippet: [  101 30522  7592  2767  1010  2129  2003  2009  2183 30523  1045  2572\n",
      "  2092  2019  2017  1029  1045  2031  1037 17109  4536  1012  3984 30522\n",
      "  1045  2572  2307  9107  1996  2374  2161 30523  1045  3298  2105  1999\n",
      "  1037  2146  2304 14994  2063  2019  2293  2023  2161   102     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "(5, 59)\n",
      "output tensor of distilbert on persona with special tokens\n",
      "persona vector :[[-1.40051171e-03  1.77102257e-02  2.65176967e-02 -1.55327126e-01\n",
      "   9.93463174e-02 -2.15759754e-01  2.09090352e-01  3.65721464e-01\n",
      "  -1.51562110e-01 -2.45026648e-01 -5.63989282e-02 -4.80085872e-02\n",
      "   1.56322476e-02  2.35959604e-01 -1.33455656e-02  2.80735791e-01\n",
      "   3.90304103e-02  3.73158395e-01  4.46285233e-02  3.48912366e-02\n",
      "   1.74803972e-01 -3.16412270e-01  1.26700640e-01  1.44125760e-01\n",
      "   1.30637854e-01 -1.48151919e-01  9.69132707e-02  1.17764249e-03\n",
      "   1.21361084e-01  1.35309994e-04  1.43389329e-01  2.81173348e-01\n",
      "   4.07292992e-02 -7.53957331e-02  7.75188357e-02 -1.57418117e-01\n",
      "   1.22086212e-01 -2.81577587e-01  7.94702619e-02  2.23326415e-01\n",
      "  -6.40412271e-02  7.53972754e-02  1.17349386e-01 -1.03508674e-01\n",
      "   1.42827779e-02 -6.65540546e-02 -3.27161670e+00  1.32080456e-02\n",
      "   6.50297105e-02 -1.18861139e-01  4.63509202e-01  8.00665915e-02\n",
      "  -2.55347490e-01  2.26705909e-01  3.21633875e-01  5.77124000e-01\n",
      "  -4.84290868e-01 -1.88325509e-01 -1.80096701e-01 -6.87083080e-02\n",
      "   4.04877424e-01  1.30100310e-01 -2.61771768e-01  1.36873901e-01\n",
      "   1.14448562e-01 -5.12284636e-02 -8.08470100e-02  2.16581300e-01\n",
      "  -1.57979622e-01  6.07894957e-01 -1.90776825e-01 -2.04717964e-01\n",
      "   2.24880517e-01 -1.71622708e-01 -1.16204396e-02 -1.51152939e-01\n",
      "   4.57170717e-02  2.20423728e-01 -7.67434537e-02  2.34457433e-01\n",
      "   1.47524834e-01  3.09799701e-01  2.94749260e-01  8.49250555e-02\n",
      "   1.91290230e-01  1.90130949e-01 -3.27706158e-01  5.91454878e-02\n",
      "   5.81692383e-02  4.44435358e-01  3.07532530e-02 -5.15369400e-02\n",
      "   9.64216366e-02  2.62804568e-01  6.59823477e-01 -4.34166759e-01\n",
      "   4.83568236e-02 -6.78862706e-02  7.94246718e-02  1.17523745e-01\n",
      "   3.42334002e-01 -9.35316458e-03  1.77338392e-01 -1.52842969e-01\n",
      "   2.59955153e-02 -6.40305281e-02  1.07250661e-01 -4.50455993e-01\n",
      "   3.64936441e-01 -1.96960843e+00  3.16669524e-01  2.71551341e-01\n",
      "  -8.37502331e-02 -4.28301513e-01 -2.30331086e-02  3.13300580e-01\n",
      "   3.01925778e-01 -3.67001481e-02  1.96857408e-01  1.72286958e-01\n",
      "  -1.49079226e-02  2.46924505e-01  5.06387763e-02 -3.39631408e-01\n",
      "   3.36180367e-02  1.99792460e-01  3.88210528e-02 -3.76638114e-01\n",
      "   6.92119375e-02  3.22582662e-01  4.51163620e-01  3.01422596e-01\n",
      "  -1.22293949e-01 -2.02922285e-01 -2.64726579e-02  3.37321311e-01\n",
      "   2.68987298e-01 -1.06705554e-01 -6.19711094e-02 -2.55839191e-02\n",
      "  -1.66904464e-01 -2.28200704e-02 -2.91272187e+00  3.21318328e-01\n",
      "   6.64162278e-01  5.03771156e-02 -1.75268191e-03  1.31599754e-01\n",
      "   6.06760234e-02 -8.56513157e-02  2.30238259e-01 -2.23403759e-02\n",
      "  -2.07334131e-01 -3.63382138e-02 -2.44026780e-01  1.60544068e-01\n",
      "  -7.89023265e-02  4.82454784e-02  2.19490349e-01  1.44852623e-01\n",
      "   5.03445268e-01 -1.61983684e-01 -3.83432731e-02 -4.14613150e-02\n",
      "  -8.71691704e-02  1.53285250e-01  1.69494748e-01  8.34025443e-03\n",
      "  -6.03007078e-02  1.42101534e-02 -1.82606727e-01  6.73734769e-03\n",
      "   6.94826365e-01 -1.98123038e-01  1.90860122e-01  3.23137268e-04\n",
      "   2.68866420e-01  3.01235169e-01  6.40405715e-02  3.24553400e-02\n",
      "  -2.18769550e-01  2.35131145e-01 -1.13364175e-01  1.53433353e-01\n",
      "   2.04315744e-02 -1.46637648e-01  4.03426051e-01 -1.88837737e-01\n",
      "   5.87430038e-02  3.66877735e-01 -2.75063515e-02 -3.19662750e-01\n",
      "  -6.16335645e-02 -1.28233328e-01  3.39688003e-01 -2.22761631e-02\n",
      "   1.31827578e-01 -2.60585368e-01  1.08949229e-01  1.56694978e-01\n",
      "  -2.56102413e-01  2.26386458e-01  1.04410984e-01  2.55213618e-01\n",
      "  -3.58743854e-02  1.07228303e+00  3.37549374e-02  2.71959975e-02\n",
      "  -1.37967588e-02  3.65386218e-01 -2.17104107e-01  2.15976797e-02\n",
      "   1.32558241e-01 -2.21954018e-01 -1.63353175e-01  1.35832205e-01\n",
      "   4.01956320e-01 -4.30193283e-02 -7.26552755e-02 -4.40341681e-02\n",
      "   3.53450209e-01  2.47364432e-01 -4.92238998e-01  6.39852732e-02\n",
      "   1.05713136e-01  1.42545670e-01 -9.23368037e-02  3.89054418e-02\n",
      "   2.02198386e-01 -1.18476450e+00  4.96708602e-02  3.29758897e-02\n",
      "   2.38382816e-02  3.71150345e-01  1.27933063e-02 -1.67870954e-01\n",
      "   5.06471097e-02 -1.32567957e-02  2.35053450e-01 -1.20785329e-02\n",
      "  -1.08723924e-01  9.55165029e-02  2.02802017e-01  2.02221274e-01\n",
      "  -5.22322774e-01  3.90065849e-01  1.19093455e-01 -6.61577582e-02\n",
      "   2.53655881e-01 -1.45692229e-01  3.37977171e-01  6.13524169e-02\n",
      "  -5.74151948e-02 -8.95716846e-02  3.92750323e-01 -1.06914811e-01\n",
      "   1.45901322e-01  4.48517837e-02 -2.27795571e-01 -4.18155044e-02\n",
      "  -4.17004377e-01 -1.16888821e-01  1.95382833e-01  1.15074120e-01\n",
      "  -3.83689612e-01  7.72705525e-02 -7.84417987e-03 -4.60315347e-01\n",
      "   2.03279421e-01  4.82975617e-02 -1.54823184e-01  6.01050630e-02\n",
      "  -7.93728173e-01 -2.94009352e+00  1.95519552e-02 -1.11665152e-01\n",
      "   2.04675019e-01  1.48132354e-01  1.44769832e-01  1.98682591e-01\n",
      "  -2.34763697e-03  4.38977689e-01 -3.71609956e-01  3.87021065e-01\n",
      "   4.00122479e-02 -1.68991089e-03  1.58658355e-01 -4.30285215e-01\n",
      "   1.17282957e-01 -4.30489555e-02 -2.08981745e-02 -1.18504740e-01\n",
      "  -1.13174200e-01 -2.09217012e-01  2.33797655e-01 -1.41429320e-01\n",
      "   3.63578111e-01 -1.28376335e-02 -1.12713613e-01 -1.04236111e-01\n",
      "  -1.53564401e-02 -4.38597873e-02  2.75248826e-01  1.27774388e-01\n",
      "  -2.01723725e-03  1.28348246e-02 -1.72008365e-01 -1.74810290e-01\n",
      "  -3.45961714e+00 -8.20407197e-02 -9.38039199e-02 -1.96434349e-01\n",
      "   1.81742478e-02  2.97078397e-02  4.10515696e-01 -1.30889341e-01\n",
      "  -1.07766390e-01 -6.19300492e-02  1.13031209e-01 -1.51255667e-01\n",
      "   1.28085509e-01  2.21592203e-01  3.06617171e-01  1.29670739e-01\n",
      "   2.63048768e-01 -1.91658497e-01  2.32485592e-01  3.41141194e-01\n",
      "  -1.81123391e-01 -4.27469611e-04  2.09675461e-01 -4.43915948e-02\n",
      "   3.17264736e-01  2.92064637e-01 -3.39421928e-01 -7.15960935e-02\n",
      "  -9.77245271e-02 -9.16751921e-02  1.11121379e-01 -2.94353426e-01\n",
      "   2.35916786e-02  1.33560002e-01 -1.80955485e-01 -1.35344639e-02\n",
      "   4.50436957e-02 -3.21753100e-02  9.73149091e-02  2.31942341e-01\n",
      "   6.66250139e-02  1.22013614e-01  1.44514084e-01 -1.74412932e-02\n",
      "   7.66685307e-01 -2.51213282e-01  1.96360007e-01  7.44015649e-02\n",
      "   3.37781198e-02 -9.29204077e-02  4.81322110e-02  3.01539749e-01\n",
      "   1.26270986e+00  1.66723430e-01 -7.42077827e-04 -2.18209371e-01\n",
      "   2.32757822e-01  3.43590498e-01  5.37594706e-02  4.80184481e-02\n",
      "   3.41128945e-01 -2.21105531e-01  2.98385143e-01 -2.51020968e-01\n",
      "  -1.26999691e-02 -3.15488338e-01  1.29460722e-01 -4.78447050e-01\n",
      "  -8.15328732e-02  1.56749543e-02 -7.77238384e-02  1.94010139e-01\n",
      "   6.89671487e-02 -9.53640342e-01 -2.46968776e-01  1.41309407e-02\n",
      "   3.90791446e-02  4.28543687e-02 -2.28913780e-02  1.92751229e-01\n",
      "  -3.39193940e-01 -3.25949043e-01 -3.71733427e-01  1.77524239e-01\n",
      "  -2.57429063e-01 -4.60799009e-01 -2.40509436e-01  1.37078762e-03\n",
      "  -5.57236850e-01 -7.41855800e-02  1.18585892e-01  3.04970086e-01\n",
      "   1.12445451e-01  3.85770589e-01  7.44240880e-02  1.00859553e-01\n",
      "   2.65604407e-01 -9.00446653e-01  3.59882444e-01 -2.00177640e-01\n",
      "  -8.83299857e-02 -1.70186102e-01  5.39817214e-02  7.70382434e-02\n",
      "  -1.47171304e-01 -1.32295907e-01 -4.31764461e-02  2.08749875e-01\n",
      "  -1.01196878e-01 -6.28793761e-02 -2.28778586e-01 -6.81035221e-04\n",
      "  -2.26248905e-01  3.20910543e-01  1.04862535e+00 -5.31264953e-02\n",
      "  -1.17556587e-01  1.63928270e-01  5.34407347e-02  1.68796033e-01\n",
      "   2.42964298e-01  6.73844367e-02 -2.00389326e-01 -1.52475655e-01\n",
      "  -2.71818221e-01 -2.02092826e-01  1.08610690e-01 -3.19499016e-01\n",
      "  -3.36241424e-01 -4.45797257e-02  2.74949037e-02 -7.31284916e-03\n",
      "  -1.77531272e-01 -4.35435325e-01  2.59489510e-02 -2.16599897e-01\n",
      "  -1.40591830e-01  8.87551084e-02  3.18043023e-01  7.39062726e-02\n",
      "   1.66605666e-01  2.22052306e-01 -2.33546004e-01  5.30844271e-01\n",
      "  -1.57678857e-01  3.92808527e-01 -7.41521120e-02 -1.55543536e-03\n",
      "   7.08948299e-02  2.57947206e-01 -1.83750570e-01 -1.26430750e-01\n",
      "  -2.90590134e-02 -3.56500685e-01  2.42057636e-01  1.61581680e-01\n",
      "   3.24006639e-02  1.26102686e-01 -3.56794260e-02  1.99516311e-01\n",
      "   3.06758851e-01 -5.67937717e-02 -1.91320884e+00  5.09106398e-01\n",
      "   9.82303172e-02  1.28393978e-01 -2.61745304e-02 -1.60395071e-01\n",
      "  -1.42225295e-01  3.64962727e-01  2.21380562e-01  2.74349660e-01\n",
      "  -2.87630502e-02 -1.77097693e-01 -1.44768536e-01  1.95171535e-01\n",
      "   3.70816439e-02 -6.92568719e-02 -1.87582627e-01 -4.80463952e-02\n",
      "  -1.71242043e-01 -2.55135536e-01 -1.73759595e-01  4.48287278e-01\n",
      "   2.05236614e-01 -7.36767873e-02  1.76196456e-01 -9.03298110e-02\n",
      "   1.49362549e-01  2.15259373e-01  2.35103905e-01  3.29736352e-01\n",
      "   9.26238149e-02 -4.11382914e-01 -5.89228868e-01 -2.74383277e-01\n",
      "   2.57294565e-01 -1.48396403e-01 -2.24023703e-02 -4.21449617e-02\n",
      "   2.39732921e-01  1.41385555e-01 -6.78860426e-01  4.57274616e-01\n",
      "   1.70195296e-01 -1.21830657e-01  3.64152700e-01 -4.29183170e-02\n",
      "  -5.83378784e-02  2.02734366e-01 -1.34707913e-01 -2.15332150e-01\n",
      "   1.36221886e-01 -1.95620254e-01 -1.37890838e-02 -7.00932145e-02\n",
      "  -2.22165912e-01 -6.70684427e-02 -2.87616700e-01  2.97812670e-01\n",
      "  -1.14464365e-01 -8.51259306e-02  2.69913971e-02 -4.11171585e-01\n",
      "  -2.83842862e-01  3.02135289e-01 -2.94287324e-01 -5.93182147e-01\n",
      "  -2.04622746e-01 -3.37418199e-01 -3.01617719e-02 -5.18345386e-02\n",
      "   4.09218550e-01 -7.11459219e-02 -3.63713622e-01  1.61731958e-01\n",
      "  -1.25431754e-02  6.68463558e-02  6.70400560e-02  1.12754576e-01\n",
      "   1.97001413e-01 -1.56411991e-01  1.14654042e-02 -4.49241877e-01\n",
      "  -2.61061549e-01  4.05574918e-01 -3.08155656e-01  2.26449087e-01\n",
      "  -3.08241993e-01 -1.63189262e-01  7.66586140e-02  1.05961807e-01\n",
      "  -3.30157816e-01 -2.44654179e-01 -3.01575959e-02 -2.38993764e-03\n",
      "  -4.73190174e-02 -2.46181674e-02 -5.16874604e-02 -2.12883115e-01\n",
      "  -7.16888756e-02  5.43487817e-03 -1.77176863e-01  4.15257573e-01\n",
      "   3.96874815e-01  5.98075837e-02  1.13201171e-01  6.74209744e-02\n",
      "   1.64159164e-01 -1.34966429e-02 -6.50068820e-02  7.11725503e-02\n",
      "  -1.56471044e-01  8.51504728e-02 -4.45564762e-02  1.59712985e-01\n",
      "   3.95503864e-02 -3.81959021e-01 -6.54625818e-02 -5.24647772e-01\n",
      "   2.00563145e+00  5.46898901e-01  1.73341334e-01 -5.07879928e-02\n",
      "   2.27311075e-01 -6.81100935e-02 -2.75468737e-01  2.11412117e-01\n",
      "  -1.12215638e-01  5.02908409e-01 -1.78680196e-01  2.28138030e-01\n",
      "  -1.69796228e-01  3.88438329e-02  5.16165853e-01  2.84552336e-01\n",
      "   8.59526917e-02 -2.50910997e-01 -5.54580152e-01 -2.14660496e-01\n",
      "  -3.39546710e-01  1.69226348e-01  2.72935182e-01  4.18628827e-02\n",
      "   5.27807921e-02  1.21689074e-01  2.10899368e-01 -3.38843539e-02\n",
      "   1.13408476e-01  1.33070022e-01  3.08132283e-02  1.18942648e-01\n",
      "   1.67661682e-01  4.45513755e-01 -2.66076684e-01  1.20329492e-01\n",
      "   7.42085949e-02 -2.22596750e-01 -4.84254241e-01  1.31841853e-01\n",
      "   2.33044744e-01 -3.25550824e-01  4.87115741e-01 -3.93061712e-02\n",
      "  -1.29730821e-01  3.98563802e-01 -2.53148139e-01 -1.83609262e-01\n",
      "   3.15948367e-01  2.71891773e-01 -6.05631098e-02  1.96526915e-01\n",
      "  -4.56263632e-01  2.27422938e-01 -1.13758236e-01 -1.49933949e-01\n",
      "  -1.34809047e-01 -2.75300860e-01  3.82216275e-03  8.18706155e-02\n",
      "  -3.81230488e-02  4.73140091e-01  1.37787998e-01  1.72839947e-02\n",
      "   1.00851990e-01  2.16271251e-01 -3.12802166e-01  1.52402431e-01\n",
      "   4.42166299e-01 -3.69637907e-01  7.17310011e-02  4.99356687e-01\n",
      "   2.14280859e-01 -2.12013841e-01  3.76552910e-01  7.56914467e-02\n",
      "   3.44332486e-01  5.51321963e-03 -3.74940932e-02 -2.36900043e+00\n",
      "   8.68031383e-02  2.23818809e-01  1.14307560e-01 -2.64796149e-02\n",
      "   3.73656780e-01  1.85585737e-01 -2.79011101e-01  6.41718358e-02\n",
      "  -1.44472942e-01  2.56057203e-01  3.55850875e-01  4.03255433e-01\n",
      "  -1.47526979e-01  1.30981728e-01 -2.01554880e-01  1.83237970e-01\n",
      "  -4.42735761e-01 -2.79514402e-01 -1.71646848e-02  1.14181750e-01\n",
      "   7.33521879e-02  8.76907185e-02 -6.65974021e-01 -3.25547725e-01\n",
      "   4.00503010e-01  6.63270652e-02 -2.82125652e-01 -5.76325171e-02\n",
      "  -8.62912238e-02  4.38737161e-02  3.57983708e-01 -3.10523868e-01\n",
      "  -9.23489481e-02  1.07175492e-01 -2.60732412e-01 -2.61080623e-01\n",
      "  -3.08343358e-02 -3.34581025e-02  6.37085736e-02 -8.60342085e-02\n",
      "   7.00745106e-01  8.10959041e-02  3.00767720e-01 -2.41442565e-02\n",
      "   6.39685392e-02  4.91616935e-01 -2.11439505e-01  2.58015007e-01\n",
      "  -2.01671809e-01 -1.79359525e-01 -5.42545319e-03  3.96369278e-01\n",
      "  -5.47096543e-02  2.13123605e-01  8.53057802e-02  2.13997632e-01\n",
      "  -6.23614341e-02  6.37510717e-02 -2.69636542e-01 -1.45483628e-01\n",
      "  -4.98235747e-02 -1.31417096e-01 -8.97720307e-02 -6.43574148e-02\n",
      "  -2.61543602e-01 -1.66156262e-01  5.76446652e-02 -1.91153333e-01\n",
      "  -1.61857337e-01 -1.48563728e-01 -9.03704837e-02  3.47187608e-01\n",
      "   1.62525833e-01  3.65195498e-02 -1.48469478e-01  4.47865665e-01\n",
      "   5.39292336e-01  8.39896649e-02  2.63534307e-01  8.27686861e-02\n",
      "  -9.22011212e-02 -1.78656414e-01 -9.70069021e-02  1.65007800e-01\n",
      "  -6.09496212e+00 -1.35553792e-01  7.98894316e-02 -2.37584352e-01\n",
      "  -2.21981034e-01 -4.38714802e-01  2.41298471e-02 -1.54263467e-01\n",
      "  -1.00688890e-01 -2.70707637e-01  9.83704254e-03  5.18250540e-02\n",
      "  -1.53465122e-01 -5.56662902e-02  5.11231899e-01  3.40956271e-01]]\n",
      "\n",
      "output tensor of distilbert on snippet with special tokens\n",
      "snippet vector: [[ 0.08949591  0.17652233 -0.02652083 ...  0.05804357  0.5995842\n",
      "   0.19670786]\n",
      " [ 0.09012872 -0.10029215  0.14276516 ...  0.00271618  0.49208724\n",
      "   0.2423582 ]\n",
      " [ 0.1421698   0.09306756  0.11931892 ... -0.04196924  0.36203274\n",
      "   0.23005415]\n",
      " [ 0.09561345  0.09986357  0.00807757 ... -0.11193436  0.4092121\n",
      "   0.25659364]\n",
      " [ 0.02482214  0.07843344  0.13647372 ... -0.1178391   0.5278622\n",
      "   0.26019254]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers as ppb  #pytorch transformers\n",
    "#from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "import random as rand\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(df):\n",
    "\n",
    "    k = 2\n",
    "    persona_convo = []\n",
    "    snippet_convo = []\n",
    "    full_doc = df[0]\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    convo_list = []\n",
    "    filtered_convo = []\n",
    "    snippet_list = []\n",
    "\n",
    "    #go through full document, and append to convo list for 8 responses\n",
    "    #(1 conversation). Then append these to a list, and get the persona and snippet\n",
    "    #from it. Finally, reset convo_list to just the current line, and filtered_convo\n",
    "\n",
    "    for line in range(0, len(full_doc)):\n",
    "        if line > 0 and line % 8 == 0:\n",
    "            #convo_list = []\n",
    "            for i in range(0, len(convo_list)):\n",
    "                filtered_convo.append(filter_for_responses(convo_list[i]))\n",
    "\n",
    "            persona_convo, snippet_convo = filter_persona_and_snippet(filtered_convo, k)\n",
    "            snippet_list.append(snippet_convo)\n",
    "            #function here to add model, tokenizer, padding, and feature extraction\n",
    "\n",
    "            convo_list = [full_doc[line]]\n",
    "            filtered_convo = []\n",
    "        else:\n",
    "            convo_list.append(full_doc[line])\n",
    "\n",
    "\n",
    "    \"\"\"print(\"persona convo: \" + str(persona_convo))\n",
    "    print()\n",
    "    print(\"snippet convo: \" + str(snippet_convo))\n",
    "    print()\"\"\"\n",
    "\n",
    "\n",
    "    tokenization_and_feature_extraction(persona_convo, snippet_convo, snippet_list)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"This function creates the DistilBertModel, tokenizes persona and snippet input,\n",
    "pads and encodes it, and extracts feature vectors\"\"\"\n",
    "def tokenization_and_feature_extraction(persona_convo, snippet_convo, snippet_list):\n",
    "    #create model, tokenizer and weights for persona and snippets\n",
    "    #make this a function called tokenize_and_encode()\n",
    "    persona_model_class, persona_tokenizer_class, persona_pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "    snippet_model_class, snippet_tokenizer_class, snippet_pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "    persona_tokenizer = persona_tokenizer_class.from_pretrained(persona_pretrained_weights)\n",
    "    persona_model = persona_model_class.from_pretrained(persona_pretrained_weights)\n",
    "\n",
    "    snippet_tokenizer = snippet_tokenizer_class.from_pretrained(snippet_pretrained_weights)\n",
    "    snippet_model = snippet_model_class.from_pretrained(snippet_pretrained_weights)\n",
    "\n",
    "    #adding tokenizer for speaker 1 and speaker 2 just for persona and snippet\n",
    "    special_tokens_dict = {'additional_special_tokens': ['<speaker-1>', '<speaker-2>']}\n",
    "    num_added_toks = persona_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    snippet_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    print(\"number of added tokens: \" + str(num_added_toks))\n",
    "    persona_model.resize_token_embeddings(len(persona_tokenizer))\n",
    "    snippet_model.resize_token_embeddings(len(snippet_tokenizer))\n",
    "\n",
    "    #persona tokenization\n",
    "    persona_convo = ' '.join(persona_convo)\n",
    "    persona_encoding = [persona_tokenizer.encode(persona_convo, add_special_tokens=True)]\n",
    "\n",
    "    #bert padding (shorter sentences with 0) with persona\n",
    "    persona_max_len = 0\n",
    "    persona_max_len = len(persona_encoding[0])\n",
    "    padded_persona = np.array([i + [0]*(persona_max_len-len(i)) for i in persona_encoding])\n",
    "\n",
    "\n",
    "    #tokenization and encoding for all snippets, as well as input tensors\n",
    "    snippet_input_ids_list = []\n",
    "\n",
    "    for i in range(0, len(snippet_list)):\n",
    "        if i < 5:\n",
    "            curr_snippet = ' '.join(snippet_list[i])\n",
    "            snippet_encoding = snippet_tokenizer.encode(curr_snippet, add_special_tokens=True)\n",
    "            snippet_input_ids_list.append(snippet_encoding)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    #now, pad the list of snippets\n",
    "    max_snippet_len = 0\n",
    "    for snippet_ids in snippet_input_ids_list:\n",
    "        if len(snippet_ids) > max_snippet_len:\n",
    "            max_snippet_len = len(snippet_ids)\n",
    "\n",
    "\n",
    "    padded_snippet_list = np.array([i + [0]*(max_snippet_len-len(i)) for i in snippet_input_ids_list])\n",
    "    for snippet in range(0, len(padded_snippet_list)):\n",
    "        print(\"encoded snippet: \" + str(padded_snippet_list[snippet]))\n",
    "        print()\n",
    "\n",
    "\n",
    "    #masking- create another variable to mask the padding we've created for persona and snippets\n",
    "    snippet_attention_mask = np.where(padded_snippet_list != 0, 1, 0)\n",
    "    print(str(snippet_attention_mask.shape))\n",
    "\n",
    "\n",
    "\n",
    "    #processing with BERT, create input tensor for persona and snippet list\n",
    "    persona_input_ids = torch.tensor(np.array(padded_persona))\n",
    "    snippet_input_ids = torch.tensor(np.array(padded_snippet_list))\n",
    "    snippet_attention_mask = torch.tensor(snippet_attention_mask)\n",
    "\n",
    "    persona_model.train()\n",
    "    snippet_model.eval()\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        persona_hidden_states = persona_model(persona_input_ids)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        snippet_hidden_states = snippet_model(snippet_input_ids, attention_mask = snippet_attention_mask)\n",
    "\n",
    "\n",
    "    #everything in last_hidden_states, now unpack 3-d output tensor.\n",
    "    #features is 2d array with sentence embeddings of all sentences in dataset.\n",
    "    #the model treats the entire persona as the \"sentence\". persona encoding\n",
    "    print(\"output tensor of distilbert on persona with special tokens\")\n",
    "    persona_features = persona_hidden_states[0][:, 0, :].detach().numpy()\n",
    "    print(\"persona vector :\" + str(persona_features))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"output tensor of distilbert on snippet with special tokens\")\n",
    "    snippet_features = snippet_hidden_states[0][:, 0, :].numpy()\n",
    "    print(\"snippet vector: \" + str(snippet_features))\n",
    "    #combine using bilinear layer, then use crossentropy loss.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"persona_zero_outputs = []\n",
    "    distilbert_size = persona_features.shape[1]\n",
    "\n",
    "    torch_persona_features = torch.from_numpy(persona_features[0])\n",
    "    torch_snippet_features = torch.from_numpy(snippet_features[0])\n",
    "\n",
    "    m = torch.nn.Bilinear(distilbert_size, distilbert_size, distilbert_size)\n",
    "    output = m(torch_persona_features, torch_snippet_features)\n",
    "\n",
    "    print(\"output from bilinear: \" + str(output))\n",
    "\n",
    "    torch_persona_features = torch.from_numpy(persona_features[0])\n",
    "    #do the above for all the snippets we have.\n",
    "    for i in range(0, len(snippet_list)):\n",
    "\n",
    "        snippet_encoding = snippet_tokenizer.encode(snippet_list[i], add_special_tokens=True)\n",
    "\n",
    "        torch_snippet_features = torch.from_numpy(snippet_features[i])\n",
    "        m = torch.nn.Bilinear(distilbert_size, distilbert_size, distilbert_size)\n",
    "        output = m(torch_persona_features, torch_snippet_features)\n",
    "        print(\"output from bilinear for snippet \" + str(i) + \" \" + str(output))\n",
    "        print()\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def filter_persona_and_snippet(filtered_convo, snippet_size):\n",
    "\n",
    "\n",
    "    rand_convo_count = 0\n",
    "    rand_convo_index = -1\n",
    "    while rand_convo_count < 1:\n",
    "        rand_convo_index = rand.randint(0, len(filtered_convo) - 1)\n",
    "        rand_convo_count += 1\n",
    "\n",
    "\n",
    "    if len(filtered_convo) > 1:\n",
    "        if rand_convo_index == len(filtered_convo) - 1:\n",
    "            snippet_convo = filtered_convo[rand_convo_index - 1:]\n",
    "            del filtered_convo[rand_convo_index - 1:]\n",
    "        else:\n",
    "            snippet_convo = filtered_convo[rand_convo_index: rand_convo_index + snippet_size]\n",
    "            del filtered_convo[rand_convo_index: rand_convo_index + snippet_size]\n",
    "\n",
    "    persona_convo = filtered_convo\n",
    "\n",
    "\n",
    "    persona_convo = add_speaker_tokens(persona_convo)\n",
    "    snippet_convo = add_speaker_tokens(snippet_convo)\n",
    "\n",
    "\n",
    "    return persona_convo, snippet_convo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_speaker_tokens(convo):\n",
    "\n",
    "    speaker_num = 2\n",
    "    new_response_str = \"\"\n",
    "    new_convo = []\n",
    "\n",
    "    for line in range(0, len(convo)):\n",
    "\n",
    "        last_speaker_index = 0\n",
    "        new_response_str = \"\"\n",
    "        for char in range(0, len(convo[line])):\n",
    "            if convo[line][char] == '\\t':\n",
    "                if speaker_num == 1:\n",
    "                    speaker_num = 2\n",
    "                    speaker_str = ' <speaker-2> '\n",
    "\n",
    "                    #add speaker 2 tag from after tab where speaker 1 left off\n",
    "                    curr_response = convo[line][last_speaker_index + 1: len(convo[line]) - 1]\n",
    "                    new_response_str += speaker_str + curr_response\n",
    "                    #print(\"new response str is : \" + new_response_str)\n",
    "\n",
    "                else:\n",
    "                    speaker_num = 1\n",
    "                    speaker_str = '<speaker-1> '\n",
    "\n",
    "                    #first speaker is 0 up to current char (the tab)\n",
    "                    curr_response = convo[line][0: char]\n",
    "                    new_response_str += speaker_str + curr_response\n",
    "                    #print(\"new response str is : \" + new_response_str)\n",
    "                    last_speaker_index = char\n",
    "\n",
    "        new_convo.append(new_response_str)\n",
    "\n",
    "    return new_convo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#filters 1 back and forth between two speakers and returns the string\n",
    "def filter_for_responses(response):\n",
    "\n",
    "    response_without_number = response[2:]\n",
    "    #print(response_without_number)\n",
    "    #print()\n",
    "    tab_count = 0\n",
    "    two_speaker_utterances = \"\"\n",
    "\n",
    "    for char in response_without_number:\n",
    "        if tab_count < 2:\n",
    "            if char == '\\t':\n",
    "                tab_count += 1\n",
    "\n",
    "            two_speaker_utterances += char\n",
    "\n",
    "    return two_speaker_utterances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_list = []\n",
    "dataframe = pd.read_csv(\"/Users/arvindpunj/Desktop/Projects/NLP lab research/Extracting-personas-for-text-generation/train_none_original.txt\",\n",
    "delimiter='\\n', header= None, error_bad_lines=False)\n",
    "\n",
    "\n",
    "main(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
